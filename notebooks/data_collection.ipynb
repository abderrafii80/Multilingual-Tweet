{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import nltk \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>context_annotations</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1858189684943265825</td>\n",
       "      <td>@wargonm Un peu toi pendant le Covid non ? Il ...</td>\n",
       "      <td>2024-11-17 16:45:19+00:00</td>\n",
       "      <td>1801562435813281793</td>\n",
       "      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1858189572150067631</td>\n",
       "      <td>Il a raison les gens ne voient que ceux que le...</td>\n",
       "      <td>2024-11-17 16:44:52+00:00</td>\n",
       "      <td>1283275292019228672</td>\n",
       "      <td>[{'domain': {'id': '10', 'name': 'Person', 'de...</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1858189551329493279</td>\n",
       "      <td>Un lanceur d'alerte a obtenu 10 Go de l'Instit...</td>\n",
       "      <td>2024-11-17 16:44:47+00:00</td>\n",
       "      <td>1840001168438689792</td>\n",
       "      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1858189437819347092</td>\n",
       "      <td>COVID, Effets Secondaires, Vacc*ns : Les derni...</td>\n",
       "      <td>2024-11-17 16:44:20+00:00</td>\n",
       "      <td>3394102223</td>\n",
       "      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1858189382278156770</td>\n",
       "      <td>C'est la technique imparable\\nde la caste au P...</td>\n",
       "      <td>2024-11-17 16:44:06+00:00</td>\n",
       "      <td>206513780</td>\n",
       "      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1858189369854595534</td>\n",
       "      <td>@lonnibesancon @Clarivate C'est toi la fraudul...</td>\n",
       "      <td>2024-11-17 16:44:03+00:00</td>\n",
       "      <td>1428599123348004864</td>\n",
       "      <td>None</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1858189363223683086</td>\n",
       "      <td>@CNEWS Non seulement il parle, il a grossit......</td>\n",
       "      <td>2024-11-17 16:44:02+00:00</td>\n",
       "      <td>1400182391487045636</td>\n",
       "      <td>[{'domain': {'id': '45', 'name': 'Brand Vertic...</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1858189359700201912</td>\n",
       "      <td>@raoult_didier vous n'êtes pas credible vous a...</td>\n",
       "      <td>2024-11-17 16:44:01+00:00</td>\n",
       "      <td>548728549</td>\n",
       "      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1858189250023354659</td>\n",
       "      <td>@VieDeCarabin J'ai simplement critiqué ton des...</td>\n",
       "      <td>2024-11-17 16:43:35+00:00</td>\n",
       "      <td>1678100076227379201</td>\n",
       "      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1858189193085686010</td>\n",
       "      <td>@LeFigaro_Sante Les effets secondaires n'exist...</td>\n",
       "      <td>2024-11-17 16:43:21+00:00</td>\n",
       "      <td>1698633392118439936</td>\n",
       "      <td>[{'domain': {'id': '123', 'name': 'Ongoing New...</td>\n",
       "      <td>français</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                               text  \\\n",
       "0  1858189684943265825  @wargonm Un peu toi pendant le Covid non ? Il ...   \n",
       "1  1858189572150067631  Il a raison les gens ne voient que ceux que le...   \n",
       "2  1858189551329493279  Un lanceur d'alerte a obtenu 10 Go de l'Instit...   \n",
       "3  1858189437819347092  COVID, Effets Secondaires, Vacc*ns : Les derni...   \n",
       "4  1858189382278156770  C'est la technique imparable\\nde la caste au P...   \n",
       "5  1858189369854595534  @lonnibesancon @Clarivate C'est toi la fraudul...   \n",
       "6  1858189363223683086  @CNEWS Non seulement il parle, il a grossit......   \n",
       "7  1858189359700201912  @raoult_didier vous n'êtes pas credible vous a...   \n",
       "8  1858189250023354659  @VieDeCarabin J'ai simplement critiqué ton des...   \n",
       "9  1858189193085686010  @LeFigaro_Sante Les effets secondaires n'exist...   \n",
       "\n",
       "                 created_at            author_id  \\\n",
       "0 2024-11-17 16:45:19+00:00  1801562435813281793   \n",
       "1 2024-11-17 16:44:52+00:00  1283275292019228672   \n",
       "2 2024-11-17 16:44:47+00:00  1840001168438689792   \n",
       "3 2024-11-17 16:44:20+00:00           3394102223   \n",
       "4 2024-11-17 16:44:06+00:00            206513780   \n",
       "5 2024-11-17 16:44:03+00:00  1428599123348004864   \n",
       "6 2024-11-17 16:44:02+00:00  1400182391487045636   \n",
       "7 2024-11-17 16:44:01+00:00            548728549   \n",
       "8 2024-11-17 16:43:35+00:00  1678100076227379201   \n",
       "9 2024-11-17 16:43:21+00:00  1698633392118439936   \n",
       "\n",
       "                                 context_annotations  language  \n",
       "0  [{'domain': {'id': '123', 'name': 'Ongoing New...  français  \n",
       "1  [{'domain': {'id': '10', 'name': 'Person', 'de...  français  \n",
       "2  [{'domain': {'id': '123', 'name': 'Ongoing New...  français  \n",
       "3  [{'domain': {'id': '123', 'name': 'Ongoing New...  français  \n",
       "4  [{'domain': {'id': '123', 'name': 'Ongoing New...  français  \n",
       "5                                               None  français  \n",
       "6  [{'domain': {'id': '45', 'name': 'Brand Vertic...  français  \n",
       "7  [{'domain': {'id': '123', 'name': 'Ongoing New...  français  \n",
       "8  [{'domain': {'id': '123', 'name': 'Ongoing New...  français  \n",
       "9  [{'domain': {'id': '123', 'name': 'Ongoing New...  français  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('../data/raw/tweets_fr.json',lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation du texte\n",
    "def normalize_text(text, language):\n",
    "    \"\"\"\n",
    "    Nettoie et normalise un texte en fonction de la langue.\n",
    "    - Supprime les caractères indésirables et unifie les styles d'écriture.\n",
    "    \"\"\"\n",
    "    if language == \"arabe\":\n",
    "        text = unicodedata.normalize(\"NFKD\", text)\n",
    "        text = re.sub(r\"[إأآا]\", \"ا\", text)\n",
    "        text = re.sub(r\"ؤ\", \"و\", text)\n",
    "        text = re.sub(r\"ئ\", \"ي\", text)\n",
    "    elif language in [\"francais\", \"anglais\"]:\n",
    "        text = text.lower()  # Met en minuscule\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Supprime les URL\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)  # Supprime les mentions\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)  # Supprime les hashtags\n",
    "    text = re.sub(r\"[^a-zA-Z\\u0621-\\u064A\\s]\", \"\", text)  # Supprime les caractères non-alphabétiques\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des tweets\n",
    "def clean_tweets(filepath, language, stopwords):\n",
    "    \"\"\"\n",
    "    Nettoie les tweets d'un fichier JSON.\n",
    "    - filepath : chemin du fichier JSON\n",
    "    - language : langue des tweets (arabe, francais, anglais)\n",
    "    - stopwords : liste des mots vides\n",
    "    \"\"\"\n",
    "    cleaned_data = []\n",
    "\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            try:\n",
    "                # Essayer de charger comme un tableau JSON\n",
    "                data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                # Si échec, charger chaque ligne comme un objet JSON\n",
    "                file.seek(0)  # Réinitialiser le curseur\n",
    "                data = [json.loads(line) for line in file]\n",
    "\n",
    "        for tweet in data:\n",
    "            # Valider que le tweet a un champ \"text\" et un champ \"id\"\n",
    "            if not isinstance(tweet, dict) or \"text\" not in tweet or \"id\" not in tweet:\n",
    "                print(f\"Tweet malformé ignoré : {tweet}\")\n",
    "                continue\n",
    "\n",
    "            text = tweet[\"text\"]\n",
    "            tweet_id = tweet[\"id\"]\n",
    "\n",
    "            # Normaliser le texte en fonction de la langue\n",
    "            clean_text = normalize_text(text, language)\n",
    "            # Supprimer les mots vides\n",
    "            clean_text = \" \".join([word for word in clean_text.split() if word not in stopwords])\n",
    "\n",
    "            # Ajouter le tweet nettoyé au résultat\n",
    "            cleaned_data.append({\"id\": tweet_id, \"text\": clean_text})\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erreur : Le fichier {filepath} est introuvable.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur inattendue lors du nettoyage : {e}\")\n",
    "\n",
    "    return cleaned_data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
